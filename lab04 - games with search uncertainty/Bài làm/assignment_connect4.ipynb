{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "Student Name: [Add your name]\n",
    "\n",
    "I have used the following AI tools: [list tools]\n",
    "\n",
    "I understand that my submission needs to be my own work: [your initials]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "* Implement adversarial search algorithms for strategic game play.\n",
    "* Analyze and optimize search in complex game spaces.\n",
    "* Design effective heuristic evaluation functions.\n",
    "* Compare performance across different agent strategies.\n",
    "* Evaluate algorithmic trade-offs between decision quality and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Total Points: Undergraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a HTML file. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
    "\n",
    "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
    "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model (result function)\n",
    "* Goal state (terminal state and utility)\n",
    "\n",
    "Describe each component and then implement it as a function that can be used by search algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Định nghĩa bài toán tìm kiếm cho Connect4\n",
    "# Định nghĩa: trạng thái là một mảng numpy kích thước (rows, cols) chứa 0 (ô trống), 1 (player red) hoặc -1 (player yellow).\n",
    "# Initial state: empty_board(rows, cols) trả về trạng thái ban đầu.\n",
    "# Actions: một hành động là chỉ số cột (0..cols-1) nơi đặt đĩa; hành động hợp lệ nếu cột đó chưa đầy.\n",
    "# Result(state, player, action): trả về bản sao của state sau khi player thả đĩa vào action.\n",
    "# Terminal(state): kiểm tra xem có người thắng hoặc bảng đầy (hòa).\n",
    "# Utility(state, player): trả về +1 nếu player thắng, -1 nếu thua, 0 nếu hòa hoặc không kết thúc.\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "\n",
    "def empty_board(rows: int = 6, cols: int = 7) -> np.ndarray:\n",
    "    \"\"\"Trả về bảng rỗng kích thước rows x cols (0 = empty).\n",
    "    Thích hợp cho mọi kích thước bảng để thử nghiệm.\n",
    "    \"\"\"\n",
    "    return np.zeros((rows, cols), dtype=int)\n",
    "\n",
    "def initial_state(rows: int = 6, cols: int = 7) -> np.ndarray:\n",
    "    \"\"\"Alias cho empty_board để biểu diễn trạng thái khởi tạo.\n",
    "    \"\"\"\n",
    "    return empty_board(rows, cols)\n",
    "\n",
    "def valid_actions(state: np.ndarray) -> List[int]:\n",
    "    \"\"\"Trả về danh sách các cột (int) có thể đặt đĩa (chưa đầy).\n",
    "    Duyệt theo cột: nếu ô trên cùng (row 0) == 0 => cột còn chỗ.\n",
    "    \"\"\"\n",
    "    rows, cols = state.shape\n",
    "    actions = [c for c in range(cols) if state[0, c] == 0]\n",
    "    return actions\n",
    "\n",
    "def result(state: np.ndarray, player: int, action: int) -> np.ndarray:\n",
    "    \"\"\"Trả về bản sao mới của state sau khi player thả đĩa vào cột action.\n",
    "    Nếu action không hợp lệ, ném ValueError.\n",
    "    \"\"\"\n",
    "    if action not in valid_actions(state):\n",
    "        raise ValueError(f'Invalid action {action} for state')\n",
    "    new_state = state.copy()\n",
    "    rows, cols = state.shape\n",
    "    # tìm hàng thấp nhất (lớn nhất index) có giá trị 0 trong cột action\n",
    "    for r in range(rows-1, -1, -1):\n",
    "        if new_state[r, action] == 0:\n",
    "            new_state[r, action] = player\n",
    "            break\n",
    "    return new_state\n",
    "\n",
    "def _check_four_in_a_row(arr: List[int], player: int) -> bool:\n",
    "    \"\"\"Helper: kiểm tra chuỗi con độ dài 4 của cùng màu trong list 1D.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for v in arr:\n",
    "        if v == player:\n",
    "            count += 1\n",
    "            if count >= 4:\n",
    "                return True\n",
    "        else:\n",
    "            count = 0\n",
    "    return False\n",
    "\n",
    "def terminal(state: np.ndarray) -> Tuple[bool, int]:\n",
    "    \"\"\"Trả về (is_terminal, winner).\n",
    "    Nếu trò chơi đã kết thúc trả về (True, winner) với winner ∈ {1, -1, 0}.\n",
    "    Nếu chưa kết thúc trả về (False, 0).\n",
    "    \"\"\"\n",
    "    winner = 0  # 0 if no winner yet, 1 or -1 indicate player who won\n",
    "    rows, cols = state.shape\n",
    "    # kiểm tra hàng ngang\n",
    "    for r in range(rows):\n",
    "        if _check_four_in_a_row(list(state[r, :]), 1):\n",
    "            return True, 1\n",
    "        if _check_four_in_a_row(list(state[r, :]), -1):\n",
    "            return True, -1\n",
    "    # kiểm tra cột dọc\n",
    "    for c in range(cols):\n",
    "        col_vals = [state[r, c] for r in range(rows)]\n",
    "        if _check_four_in_a_row(col_vals, 1):\n",
    "            return True, 1\n",
    "        if _check_four_in_a_row(col_vals, -1):\n",
    "            return True, -1\n",
    "    # kiểm tra đường chéo (\n",
    "    # các đường chéo có thể được trích xuất bằng cách cố định (r0,c0) và đi xuống phải\n",
    "    for r0 in range(rows):\n",
    "        for c0 in range(cols):\n",
    "            diag = []\n",
    "            r, c = r0, c0\n",
    "            while r < rows and c < cols:\n",
    "                diag.append(state[r, c])\n",
    "                r += 1\n",
    "                c += 1\n",
    "            if _check_four_in_a_row(diag, 1):\n",
    "                return True, 1\n",
    "            if _check_four_in_a_row(diag, -1):\n",
    "                return True, -1\n",
    "    # kiểm tra đường chéo (/)\n",
    "    for r0 in range(rows):\n",
    "        for c0 in range(cols):\n",
    "            diag = []\n",
    "            r, c = r0, c0\n",
    "            while r < rows and c >= 0:\n",
    "                diag.append(state[r, c])\n",
    "                r += 1\n",
    "                c -= 1\n",
    "            if _check_four_in_a_row(diag, 1):\n",
    "                return True, 1\n",
    "            if _check_four_in_a_row(diag, -1):\n",
    "                return True, -1\n",
    "    # nếu bảng đầy thì kết thúc hòa\n",
    "    if not any(state[0, c] == 0 for c in range(cols)):\n",
    "        return True, 0\n",
    "    return False, 0\n",
    "\n",
    "def utility(state: np.ndarray, player: int) -> int:\n",
    "    \"\"\"Trả về utility từ quan điểm của player: +1 nếu player thắng, -1 nếu thua, 0 khác.\n",
    "    \"\"\"\n",
    "    is_term, winner = terminal(state)\n",
    "    if not is_term:\n",
    "        return 0\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    return 1 if winner == player else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: ~3^(rows*cols) upper bound (3^42 for 6x7) but actual reachable states far fewer due to gravity constraints\n"
     ]
    }
   ],
   "source": [
    "# Ước lượng kích thước không gian trạng thái cho Connect4:\n",
    "# Với bảng 6x7, mỗi ô có thể là -1, 0 hoặc 1, nên trên lý thuyết là 3^(6*7) trạng thái,\n",
    "# tức là 3^42 ≈ 1.5e20. Tuy nhiên nhiều trạng thái không thể xảy ra do tính chất rơi xuống của đĩa,\n",
    "# và còn phải xét quy trình chơi (lượt đi). Thực tế không gian trạng thái khả thi nhỏ hơn nhiều nhưng vẫn rất lớn.\n",
    "# Kết luận: trạng thái khả dĩ cực lớn (nghịch lý so với brute-force).\n",
    "print('Estimate: ~3^(rows*cols) upper bound (3^42 for 6x7) but actual reachable states far fewer due to gravity constraints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game-tree size approx b^d, e.g., 7^42 upper bound — infeasible for brute-force minimax\n"
     ]
    }
   ],
   "source": [
    "# Ước lượng kích thước cây trò chơi (game tree) cho minimax:\n",
    "# Nếu coi branching factor trung bình ≈ b và độ sâu tối đa của trò chơi ≈ d (số ô tối đa),\n",
    "# thì số node ~ b^d. Với bảng 6x7, b ≈ 7 lúc đầu và d ≤ 42, nên cây rất lớn (7^42 ≈ 1.6e35)\n",
    "# Vì vậy cần cắt tỉa (alpha-beta) và/hoặc giới hạn độ sâu + heuristic để thực hiện được trong thời gian hợp lý.\n",
    "print('Game-tree size approx b^d, e.g., 7^42 upper bound — infeasible for brute-force minimax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [25 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Demo nhỏ: dùng hàm empty_board đã được định nghĩa ở trên (rows, cols).\n",
    "# Tránh định nghĩa lại empty_board ở đây để không ghi đè signature mong muốn.\n",
    "print(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization code by Randolph Rankin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(board):\n",
    "    plt.axes()\n",
    "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
    "    circles=[]\n",
    "    for i,row in enumerate(board):\n",
    "        for j,val in enumerate(row):\n",
    "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
    "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
    "\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    for circle in circles:\n",
    "        plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.show()\n",
    "    \n",
    "board = [[0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0,-1,-1, 1,-1, 0, 0]]\n",
    "visualize(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* A check for available actions in each state `actions(state)`.\n",
    "* The transition model `result(state, player, action)`.\n",
    "* Check for terminal states `terminal(state)`.\n",
    "* The utility function `utility(state, player)`.\n",
    "\n",
    "The player argument is used so your agent can play red or yellow.\n",
    "Make sure that all these functions work with boards of different sizes (number of columns and rows).\n",
    "You can follow the [tic-tac-toe example from class.](https://colab.research.google.com/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_definitions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Helper functions và môi trường chơi cơ bản cho Connect4\n",
    "# Bao gồm: actions(state), result(state,player,action) đã cài ở trên (nhưng ta có thể thêm một lớp môi trường đơn giản).\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "class Connect4Env:\n",
    "    \"\"\"Môi trường Connect4 đơn giản để dùng trong thử nghiệm: lưu trạng thái, cho phép chơi một bước và kiểm tra kết thúc.\n",
    "    \"\"\"\n",
    "    def __init__(self, rows: int = 6, cols: int = 7):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.state = empty_board(rows, cols)\n",
    "        self.current_player = 1\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        self.state = empty_board(self.rows, self.cols)\n",
    "        self.current_player = 1\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action: int) -> Tuple[np.ndarray, int, bool, dict]:\n",
    "        \"\"\"Thực hiện action cho current_player, trả về (state, reward, done, info).\n",
    "        Reward sử dụng hàm utility cho player vừa di chuyển.\n",
    "        \"\"\"\n",
    "        if action not in valid_actions(self.state):\n",
    "            raise ValueError('Invalid action')\n",
    "        self.state = result(self.state, self.current_player, action)\n",
    "        done, winner = terminal(self.state)\n",
    "        reward = 0\n",
    "        if done:\n",
    "            if winner == 0:\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = 1 if winner == self.current_player else -1\n",
    "        info = {'winner': winner}\n",
    "        # chuyển người chơi nếu trò chơi chưa kết thúc\n",
    "        if not done:\n",
    "            self.current_player *= -1\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def legal_actions(self):\n",
    "        return valid_actions(self.state)\n",
    "\n",
    "# Hàm giúp chạy một trận giữa hai agent functions\n",
    "def play_game(agent1: Callable, agent2: Callable, env: Connect4Env, verbose: bool = False) -> int:\n",
    "    \"\"\"Cho hai agent (agent(board, player)) chơi trên env; trả về winner (1, -1 or 0 for draw).\n",
    "    Agent1 sẽ chơi player=1 (red) và agent2 chơi player=-1 (yellow).\n",
    "    \"\"\"\n",
    "    env.reset()\n",
    "    agents = {1: agent1, -1: agent2}\n",
    "    while True:\n",
    "        player = env.current_player\n",
    "        board = env.state\n",
    "        action = agents[player](board.copy(), player=player)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        if verbose:\n",
    "            print(f'Player {player} -> action {action}, reward={reward}, done={done}')\n",
    "        if done:\n",
    "            return info.get('winner', 0)\n",
    "\n",
    "# Random agent implementation (signature required)\n",
    "import random\n",
    "def random_player(board: np.ndarray, player: int = 1) -> int:\n",
    "    \"\"\"Agent ngẫu nhiên: chọn một hành động hợp lệ ngẫu nhiên.\n",
    "    - board: numpy array trạng thái hiện tại\n",
    "    - player: 1 hoặc -1\n",
    "    Trả về: chỉ số cột (int) để đặt đĩa.\n",
    "    \"\"\"\n",
    "    actions = valid_actions(board)\n",
    "    if not actions:\n",
    "        raise ValueError('No legal actions available')\n",
    "    return random.choice(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = 1): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ: cho 2 agent ngẫu nhiên chơi 1000 ván và đếm kết quả.\n",
    "def tournament_random_vs_random(n_games: int = 1000, rows: int = 6, cols: int = 7):\n",
    "    env = Connect4Env(rows, cols)\n",
    "    results = {1: 0, -1: 0, 0: 0}\n",
    "    for i in range(n_games):\n",
    "        winner = play_game(random_player, random_player, env, verbose=False)\n",
    "        results[winner] += 1\n",
    "    return results\n",
    "\n",
    "# Nếu bạn muốn chạy nhanh thử nghiệm nhỏ:\n",
    "# print(tournament_random_vs_random(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả sau 1000 ván (1, -1, 0): {1: 561, -1: 435, 0: 4}\n"
     ]
    }
   ],
   "source": [
    "# Chạy giải đấu 1000 trận giữa hai agent ngẫu nhiên (Task 2 experiment).\n",
    "# Lưu ý: tùy vào hiệu năng, bạn có thể giảm số trận để chạy nhanh.\n",
    "results = tournament_random_vs_random(1000)\n",
    "print('Kết quả sau 1000 ván (1, -1, 0):', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
    "\n",
    "### Implement the Search [20 points] \n",
    "\n",
    "Implement minimax search starting from a given board for specifying the player.\n",
    "\n",
    "__Important Notes:__ \n",
    "* You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
    "This is essential to be able play against agents from other students later.\n",
    "* The game tree for a $6 \\times 7$ board is huge and optimal algorithms need to visit each or a large percentage of all nodes in the tree. You can experiment with smaller boards like a $4 \\times 4$ board first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Minimax search with Alpha-Beta pruning\n",
    "# Implement minimax/alpha-beta as một hàm quyết định (minimax_decision) và một lớp agent lưu trạng thái để gọi như agent(board, player).\n",
    "import time\n",
    "from typing import Optional, Callable, List\n",
    "\n",
    "def minimax_decision(board: np.ndarray, player: int, max_depth: Optional[int] = None, order_actions_fn: Optional[Callable] = None, eval_fn: Optional[Callable] = None) -> int:\n",
    "    \"\"\"Trả về hành động tốt nhất cho player bằng Minimax + Alpha-Beta.\n",
    "    - board: numpy array trạng thái hiện tại\n",
    "    - player: người đang đi (1 hoặc -1)\n",
    "    - max_depth: nếu không None thì cắt ở độ sâu đó (depth tính theo số lượt từ root, root depth=0)\n",
    "    - order_actions_fn: hàm tùy chọn để sắp xếp hành động nhằm cải thiện pruning\n",
    "    - eval_fn: hàm heuristic(state, player) được gọi khi cắt (cutoff)\n",
    "    \"\"\"\n",
    "    nodes = 0\n",
    "    def max_value(state, alpha, beta, depth):\n",
    "        nonlocal nodes\n",
    "        nodes += 1\n",
    "        is_term, winner = terminal(state)\n",
    "        if is_term:\n",
    "            return utility(state, player)\n",
    "        if max_depth is not None and depth >= max_depth:\n",
    "            return eval_fn(state, player) if eval_fn is not None else utility(state, player)\n",
    "        v = -float('inf')\n",
    "        actions = valid_actions(state)\n",
    "        if order_actions_fn is not None:\n",
    "            actions = order_actions_fn(state, player, actions)\n",
    "        for a in actions:\n",
    "            v = max(v, min_value(result(state, player, a), alpha, beta, depth+1))\n",
    "            alpha = max(alpha, v)\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "        return v\n",
    "\n",
    "    def min_value(state, alpha, beta, depth):\n",
    "        nonlocal nodes\n",
    "        nodes += 1\n",
    "        is_term, winner = terminal(state)\n",
    "        if is_term:\n",
    "            return utility(state, player)\n",
    "        if max_depth is not None and depth >= max_depth:\n",
    "            return eval_fn(state, -player) if eval_fn is not None else utility(state, player)\n",
    "        v = float('inf')\n",
    "        actions = valid_actions(state)\n",
    "        if order_actions_fn is not None:\n",
    "            actions = order_actions_fn(state, -player, actions)\n",
    "        for a in actions:\n",
    "            v = min(v, max_value(result(state, -player, a), alpha, beta, depth+1))\n",
    "            beta = min(beta, v)\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "        return v\n",
    "\n",
    "    best_action = None\n",
    "    best_val = -float('inf')\n",
    "    start = time.perf_counter()\n",
    "    actions = valid_actions(board)\n",
    "    if order_actions_fn is not None:\n",
    "        actions = order_actions_fn(board, player, actions)\n",
    "    for a in actions:\n",
    "        v = min_value(result(board, player, a), -float('inf'), float('inf'), 1)\n",
    "        if v > best_val:\n",
    "            best_val = v\n",
    "            best_action = a\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return best_action\n",
    "\n",
    "class MinimaxAgent:\n",
    "    \"\"\"Agent dựa trên Minimax + Alpha-Beta. Có thể cấu hình độ sâu cắt, strategy sắp xếp hành động và heuristic eval_fn.\n",
    "    Gọi như: agent(board, player) để phù hợp với môi trường.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth: Optional[int] = None, order_actions_fn: Optional[Callable] = None, eval_fn: Optional[Callable] = None):\n",
    "        self.max_depth = max_depth\n",
    "        self.order_actions_fn = order_actions_fn\n",
    "        self.eval_fn = eval_fn\n",
    "\n",
    "    def __call__(self, board: np.ndarray, player: int = 1) -> int:\n",
    "        return minimax_decision(board, player, max_depth=self.max_depth, order_actions_fn=self.order_actions_fn, eval_fn=self.eval_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimax chọn cột: 3\n"
     ]
    }
   ],
   "source": [
    "# Task 3 experiments: kiểm tra một vài board mẫu để xem agent có phát hiện nước thắng ngay lập tức hay không.\n",
    "# Tạo board mẫu: ví dụ một board nơi player=1 có thể thắng bằng cách thả vào cột cụ thể.\n",
    "# Lưu ý: index cột bắt đầu từ 0.\n",
    "# Board mẫu: 6x7 với vài quân đã nằm sẵn\n",
    "board = empty_board(6,7)\n",
    "# đặt một tình huống nơi player 1 có 3 nối và cần 1 để thắng ngang\n",
    "board[5,0] = 1\n",
    "board[5,1] = 1\n",
    "board[5,2] = 1\n",
    "# bảo đảm cột 3 trống ở đáy để thắng\n",
    "visualize(board)\n",
    "agent = MinimaxAgent(max_depth=4)  # depth nhỏ ban đầu để chạy nhanh\n",
    "best = agent(board, player=1)\n",
    "print('Minimax chọn cột:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns/rows. Explain why using this algorithm on a standard $6 \\times 7$ board is not feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain: 1 time: 0.11823850002838299\n",
      "ordered: 3 time: 0.019431900000199676\n"
     ]
    }
   ],
   "source": [
    "# Move ordering và đo thời gian thực hiện nước đi\n",
    "import time\n",
    "\n",
    "def center_first_order(state, player, actions):\n",
    "    # ưu tiên các cột gần giữa bảng (thường tốt cho Connect4)\n",
    "    cols = state.shape[1]\n",
    "    center = (cols - 1) / 2.0\n",
    "    return sorted(actions, key=lambda a: abs(a - center))\n",
    "\n",
    "def time_agent_move(agent_fn, board, player=1):\n",
    "    start = time.perf_counter()\n",
    "    a = agent_fn(board, player=player)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return a, elapsed\n",
    "\n",
    "# Tạo board phức tạp hơn để thử nghiệm thời gian\n",
    "test_board = empty_board(6,7)\n",
    "# làm đầy một vài cột để tăng branching\n",
    "for c in [0,1,2,4,5]:\n",
    "    for r in range(3):\n",
    "        test_board[5-r, c] = 1 if r % 2 == 0 else -1\n",
    "\n",
    "# Agent không dùng ordering\n",
    "agent_plain = MinimaxAgent(max_depth=4, order_actions_fn=None)\n",
    "a1, t1 = time_agent_move(agent_plain, test_board, player=1)\n",
    "# Agent dùng ordering trung tâm\n",
    "agent_ordered = MinimaxAgent(max_depth=4, order_actions_fn=center_first_order)\n",
    "a2, t2 = time_agent_move(agent_ordered, test_board, player=1)\n",
    "print('plain:', a1, 'time:', t1)\n",
    "print('ordered:', a2, 'time:', t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering [5 points]\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth, time_plain, time_ordered\n",
      "(2, 0.01076380000449717, 0.009926199971232563)\n",
      "(3, 0.034808100026566535, 0.015500899986363947)\n"
     ]
    }
   ],
   "source": [
    "# Move-ordering: so sánh thời gian thực thi với/không có ordering trên các độ sâu khác nhau\n",
    "import time\n",
    "def measure_ordering(board, player, depths=(2,3,4)):\n",
    "    results = []\n",
    "    for d in depths:\n",
    "        a_plain, t_plain = None, None\n",
    "        a_ord, t_ord = None, None\n",
    "        agent_plain = MinimaxAgent(max_depth=d, order_actions_fn=None)\n",
    "        agent_ord = MinimaxAgent(max_depth=d, order_actions_fn=center_first_order)\n",
    "        start = time.perf_counter(); a_plain = agent_plain(board, player=player); t_plain = time.perf_counter()-start\n",
    "        start = time.perf_counter(); a_ord = agent_ord(board, player=player); t_ord = time.perf_counter()-start\n",
    "        results.append((d, t_plain, t_ord))\n",
    "    return results\n",
    "\n",
    "# Thử trên một board thử nghiệm (đã tạo ở ô trước là test_board)\n",
    "res = measure_ordering(test_board, player=1, depths=(2,3))\n",
    "print('depth, time_plain, time_ordered')\n",
    "for row in res:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves [5 points]\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening pick (center-preference): 3\n"
     ]
    }
   ],
   "source": [
    "# The first few moves: đề xuất chính sách mở đầu đơn giản và hiện thực hóa nó.\n",
    "# Gợi ý: ở Connect4, các cột giữa thường mạnh hơn; ta có thể dùng heuristic opening: chọn cột giữa nếu có thể.\n",
    "def opening_policy(board: np.ndarray, player: int = 1) -> int:\n",
    "    cols = board.shape[1]\n",
    "    center = cols // 2\n",
    "    actions = valid_actions(board)\n",
    "    if center in actions:\n",
    "        return center\n",
    "    # nếu không có giữa, chọn cột gần giữa nhất\n",
    "    actions_sorted = sorted(actions, key=lambda a: abs(a - center))\n",
    "    return actions_sorted[0]\n",
    "\n",
    "# Ví dụ: mở đầu trên bảng rỗng 6x7\n",
    "b = empty_board(6,7)\n",
    "print('Opening pick (center-preference):', opening_policy(b, player=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime [5 points]\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a $4 \\times 4$ board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 8, -1: 0, 0: 2}\n"
     ]
    }
   ],
   "source": [
    "# Playtime: cho Minimax (depth-limited) chơi với Random trên board nhỏ 4x4\n",
    "def play_minimax_vs_random(n_games: int = 10, rows: int = 4, cols: int = 4, depth: int = 4):\n",
    "    env = Connect4Env(rows, cols)\n",
    "    mm_agent = MinimaxAgent(max_depth=depth, order_actions_fn=None)\n",
    "    results = {1: 0, -1: 0, 0: 0}\n",
    "    for i in range(n_games):\n",
    "        winner = play_game(mm_agent, random_player, env, verbose=False)\n",
    "        results[winner] += 1\n",
    "    return results\n",
    "\n",
    "print(play_minimax_vs_random(10, 4, 4, depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search\n",
    "\n",
    "### Heuristic evaluation function [15 points]\n",
    "\n",
    "Define and implement a heuristic evaluation function. Make sure that the heuristic value stays in the correct range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Heuristic evaluation function (window-based, stronger)\n",
    "def heuristic_eval(state: np.ndarray, player: int) -> float:\n",
    "    \"\"\"Window-based heuristic: quét mọi cửa sổ độ dài 4 (hàng, cột, 2 đường chéo).\n",
    "    Trả điểm cho patterns: 4-in-row (very large), open-3, closed-3, open-2; cộng bonus trung tâm.\n",
    "    Kết quả chuẩn hóa về [-1,1].\n",
    "    \"\"\"\n",
    "    rows, cols = state.shape\n",
    "    def windows_of_length_4(s):\n",
    "        # rows\n",
    "        for r in range(rows):\n",
    "            for c in range(cols - 4 + 1):\n",
    "                yield [s[r, c+i] for i in range(4)]\n",
    "        # cols\n",
    "        for c in range(cols):\n",
    "            for r in range(rows - 4 + 1):\n",
    "                yield [s[r+i, c] for i in range(4)]\n",
    "        # diag \\ (down-right)\n",
    "        for r in range(rows - 4 + 1):\n",
    "            for c in range(cols - 4 + 1):\n",
    "                yield [s[r+i, c+i] for i in range(4)]\n",
    "        # anti-diag / (down-left)\n",
    "        for r in range(rows - 4 + 1):\n",
    "            for c in range(3, cols):\n",
    "                yield [s[r+i, c-i] for i in range(4)]\n",
    "    # weights\n",
    "    W4 = 1000.0\n",
    "    W_open3 = 50.0\n",
    "    W_3 = 10.0\n",
    "    W_open2 = 3.0\n",
    "    W_center = 1.0\n",
    "    score = 0.0\n",
    "    def eval_window(win, p):\n",
    "        cnt_p = sum(1 for x in win if x == p)\n",
    "        cnt_opp = sum(1 for x in win if x == -p)\n",
    "        if cnt_p == 4: return W4\n",
    "        if cnt_opp == 4: return -W4\n",
    "        if cnt_p == 3 and cnt_opp == 0: return W_open3\n",
    "        if cnt_opp == 3 and cnt_p == 0: return -W_open3\n",
    "        if cnt_p == 2 and cnt_opp == 0: return W_open2\n",
    "        if cnt_opp == 2 and cnt_p == 0: return -W_open2\n",
    "        return 0.0\n",
    "    for win in windows_of_length_4(state):\n",
    "        score += eval_window(win, player)\n",
    "    # center control bonus\n",
    "    center_col = cols // 2\n",
    "    for r in range(rows):\n",
    "        if state[r, center_col] == player: score += W_center\n",
    "        elif state[r, center_col] == -player: score -= W_center\n",
    "    # normalize\n",
    "    approx_max = W4 + (W_open3 * 10) + (W_open2 * 20) + (W_center * rows)\n",
    "    val = max(-1.0, min(1.0, score / approx_max))\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting Off Search [10 points]\n",
    "\n",
    "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting off search: sử dụng minimax_decision với eval_fn (không dùng monkey-patch)\n",
    "def minimax_with_cutoff(board: np.ndarray, player: int, cutoff_depth: int, order_actions_fn: Optional[Callable]=None) -> int:\n",
    "    \"\"\"Wrapper: gọi minimax_decision với eval_fn=heuristic_eval để cắt ở cutoff_depth.\n",
    "    Trả về action (int).\n",
    "    \"\"\"\n",
    "    return minimax_decision(board, player, max_depth=cutoff_depth, order_actions_fn=order_actions_fn, eval_fn=heuristic_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center heuristic for player 1: 0.0006385696040868455\n",
      "h-almost heuristic for player 1: 0.03384418901660281\n"
     ]
    }
   ],
   "source": [
    "# Task 4 experiment: kiểm tra heuristic trên các board mẫu (tức là xem heuristic đánh giá như thế nào)\n",
    "samples = []\n",
    "# sample 1: center occupied by player 1\n",
    "s1 = empty_board(6,7)\n",
    "s1[5,3] = 1\n",
    "samples.append(('center', s1))\n",
    "# sample 2: near-win for player 1 horizontally\n",
    "s2 = empty_board(6,7)\n",
    "s2[5,0]=1; s2[5,1]=1; s2[5,2]=1\n",
    "samples.append(('h-almost', s2))\n",
    "for name, b in samples:\n",
    "    print(name, 'heuristic for player 1:', heuristic_eval(b, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size (4, 4) time 0.004078500031027943\n",
      "size (5, 5) time 0.011872900009620935\n",
      "size (6, 7) time 0.04363440000452101\n"
     ]
    }
   ],
   "source": [
    "# Task 4 timing: đo thời gian thực hiện nước đi trên các kích thước bảng khác nhau với cutoff depth cố định\n",
    "import time\n",
    "def measure_time_for_size(rows, cols, depth=4):\n",
    "    env = Connect4Env(rows, cols)\n",
    "    b = empty_board(rows, cols)\n",
    "    agent = MinimaxAgent(max_depth=depth, eval_fn=heuristic_eval)\n",
    "    start = time.perf_counter()\n",
    "    a = agent(b, player=1)\n",
    "    return time.perf_counter()-start\n",
    "for size in [(4,4),(5,5),(6,7)]:\n",
    "    t = measure_time_for_size(size[0], size[1], depth=3)\n",
    "    print('size', size, 'time', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime [5 points]\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner (deep vs shallow): 1\n"
     ]
    }
   ],
   "source": [
    "# Let two heuristic search agents (different cutoff depth) play once on a 6x7 board\n",
    "env = Connect4Env(6,7)\n",
    "agent_deep = MinimaxAgent(max_depth=4, eval_fn=heuristic_eval)\n",
    "agent_shallow = MinimaxAgent(max_depth=2, eval_fn=heuristic_eval)\n",
    "winner = play_game(agent_deep, agent_shallow, env, verbose=False)\n",
    "print('Winner (deep vs shallow):', winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [up to +10 bonus point will be awarded separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureMC pick: 2\n"
     ]
    }
   ],
   "source": [
    "# Pure Monte Carlo Search (graduate bonus):\n",
    "import random\n",
    "\n",
    "def rollout_random(b, player):\n",
    "    \"\"\"Thực hiện một rollout ngẫu nhiên từ trạng thái b; trả về winner.\"\"\"\n",
    "    env = Connect4Env(b.shape[0], b.shape[1])\n",
    "    env.state = b.copy()\n",
    "    env.current_player = player\n",
    "    while True:\n",
    "        actions = env.legal_actions()\n",
    "        if not actions:\n",
    "            # no legal actions -> draw\n",
    "            return 0\n",
    "        a = random.choice(actions)\n",
    "        state, reward, done, info = env.step(a)\n",
    "        if done:\n",
    "            return info.get('winner', 0)\n",
    "    # fallback (shouldn't reach)\n",
    "    return 0\n",
    "\n",
    "def pure_monte_carlo(b, player, n_trials=200):\n",
    "    # trả về action có tỉ lệ thắng cao nhất khi thực hiện n_trials rollout cho mỗi action\n",
    "    actions = valid_actions(b)\n",
    "    if not actions:\n",
    "        return None\n",
    "    scores = {a: 0 for a in actions}\n",
    "    for a in actions:\n",
    "        for t in range(n_trials):\n",
    "            newb = result(b, player, a)\n",
    "            winner = rollout_random(newb, -player)\n",
    "            if winner == player:\n",
    "                scores[a] += 1\n",
    "    # pick argmax (break ties randomly)\n",
    "    max_score = max(scores.values())\n",
    "    best_actions = [a for a, s in scores.items() if s == max_score]\n",
    "    return random.choice(best_actions)\n",
    "\n",
    "# quick test on a small board:\n",
    "b = empty_board(4,4)\n",
    "print('PureMC pick:', pure_monte_carlo(b, 1, n_trials=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "Use your Monte Carlo Search to determine what the best first move for red is? Describe under what assumptions this is the \"best\" first move.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best first move by Pure Monte Carlo (approx): 3\n"
     ]
    }
   ],
   "source": [
    "# Best First Move using Monte Carlo: chạy pure_monte_carlo cho board rỗng và thống kê các lựa chọn\n",
    "b = empty_board(6,7)\n",
    "best_move = pure_monte_carlo(b, 1, n_trials=200)\n",
    "print('Best first move by Pure Monte Carlo (approx):', best_move)\n",
    "# Lưu ý: kết quả phụ thuộc vào số trials; nhiều trials -> ổn định hơn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
